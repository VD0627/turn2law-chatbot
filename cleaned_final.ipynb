{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VD0627/turn2law-chatbot/blob/main/cleaned_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHVcRwUhf0iA",
        "outputId": "16118d5d-93c1-4cd7-c687-a6d63326fff0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Lho4NAIfcFs"
      },
      "outputs": [],
      "source": [
        "# List all files in Google Drive\n",
        "import os\n",
        "for root, dirs, files in os.walk('/content/drive/MyDrive/'):\n",
        "    for file in files:\n",
        "        if file.endswith('.ipynb'):  # Looking for all ipynb files\n",
        "            print(os.path.join(root, file))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "cj3YxJW4eDoD",
        "outputId": "681d4950-c8e2-4cae-b335-c328c948c589"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/final.ipynb'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-a2aa91e2bc2e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnotebook_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/final.ipynb'\u001b[0m  \u001b[0;31m# Path to your notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnotebook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnbformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnotebook_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Remove the 'widgets' metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/final.ipynb'"
          ]
        }
      ],
      "source": [
        "import nbformat\n",
        "\n",
        "# Load the notebook\n",
        "notebook_path = '/content/final.ipynb'  # Path to your notebook\n",
        "notebook = nbformat.read(open(notebook_path, 'r'), as_version=4)\n",
        "\n",
        "# Remove the 'widgets' metadata\n",
        "if 'metadata' in notebook and 'widgets' in notebook['metadata']:\n",
        "    del notebook['metadata']['widgets']\n",
        "\n",
        "# Save the cleaned notebook back to the same location\n",
        "cleaned_notebook_path = '/content/cleaned_final.ipynb'\n",
        "with open(cleaned_notebook_path, 'w') as f:\n",
        "    nbformat.write(notebook, f)\n",
        "\n",
        "# Optional: Download the cleaned notebook to your local system\n",
        "from google.colab import files\n",
        "files.download(cleaned_notebook_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmP742cCgVcK"
      },
      "outputs": [],
      "source": [
        "# ✅ Step 1: Install Required Packages\n",
        "!pip install -q sentence-transformers faiss-cpu transformers gradio pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuppe-KvLUOn"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import base64\n",
        "import re\n",
        "\n",
        "# ✅ Convert logo to base64\n",
        "def image_to_base64(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
        "\n",
        "# ✅ Set logo path\n",
        "logo_path = \"logo_assets/logo.png\"  # Make sure your logo is extracted here\n",
        "logo_base64 = image_to_base64(logo_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJFoDqhnH-gR"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "\n",
        "def image_to_base64(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        data = f.read()\n",
        "    return base64.b64encode(data).decode(\"utf-8\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcnVj48DghTl",
        "outputId": "cbf8e76b-8bb0-470b-e806-527fb8a1027d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.5)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf\n",
        "!pip install faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgQKq5b2h89y",
        "outputId": "4cf570a7-be2a-4f98-f6c9-4cc004bbb866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/27/94/3266821f65b92b3138631e9c8e7fe1fb513804ac934485a8d05776e1dd43/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q sentence-transformers faiss-cpu transformers gradio pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpqOkqc5gVcL"
      },
      "outputs": [],
      "source": [
        "# ✅ Step 2: Import Librariesimport pandas as pd\n",
        "import numpy as np\n",
        "import faiss\n",
        "import pickle\n",
        "import gradio as gr\n",
        "import re\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1ONL43qGGBP",
        "outputId": "5ea0484d-341e-4623-a60a-8e8fd90d8323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.33.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.44.1 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQf03Ta-DAm0",
        "outputId": "969f597b-c545-42af-cc8d-359115274c3e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-10 14:27:10.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-10 14:27:10.727 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-10 14:27:11.035 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-04-10 14:27:11.039 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-10 14:27:11.042 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-10 14:27:11.045 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-10 14:27:11.048 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-10 14:27:11.050 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-10 14:27:11.053 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-10 14:27:11.055 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "DeltaGenerator()"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import streamlit as st\n",
        "\n",
        "# ✅ Extract logo from ZIP file\n",
        "with zipfile.ZipFile(\"logopng.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"logo_assets\")\n",
        "\n",
        "# ✅ Get the image path\n",
        "logo_path = None\n",
        "for file in os.listdir(\"logo_assets\"):\n",
        "    if file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        logo_path = os.path.join(\"logo_assets\", file)\n",
        "        break\n",
        "\n",
        "# ✅ Display Turn2Bot branding in Streamlit\n",
        "if logo_path:\n",
        "    st.image(logo_path, width=70)\n",
        "\n",
        "st.markdown(\"<h2 style='color:#1A237E;'>🤖 <b>Turn2Bot</b> – Your Legal Companion ⚖️</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "st.markdown(\n",
        "    \"<p style='font-size:14px; color:#555;'>Ask any legal question under Indian law and get instant AI-powered guidance. \"\n",
        "    \"<br><b>Note:</b> This is not professional legal advice. Always consult a certified lawyer for official matters.</p>\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "st.markdown(\"---\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqUgtCjwDh3H",
        "outputId": "558e48cc-2003-463e-ca02-ef973ac152f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "📄 Extracting PDFs: 100%|██████████| 4/4 [00:07<00:00,  1.85s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Corpus created with 2899 chunks.\n"
          ]
        }
      ],
      "source": [
        "#step3\n",
        "import fitz  # PyMuPDF\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ✅ List all your PDF paths\n",
        "pdf_paths = [\"/content/ds1.pdf\", \"/content/ds2.pdf\", \"/content/ds3.pdf\", \"/content/ds4.pdf\"]\n",
        "\n",
        "# ✅ Function to extract text from a single PDF\n",
        "def extract_text_from_pdf(path):\n",
        "    text = \"\"\n",
        "    with fitz.open(path) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "    return text\n",
        "\n",
        "# ✅ Extract from all PDFs\n",
        "all_text = \"\"\n",
        "for path in tqdm(pdf_paths, desc=\"📄 Extracting PDFs\"):\n",
        "    all_text += extract_text_from_pdf(path) + \"\\n\\n\"\n",
        "\n",
        "# ✅ Split into chunks (adjust size as needed)\n",
        "def chunk_text(text, max_chunk_size=1000):\n",
        "    chunks = []\n",
        "    while len(text) > max_chunk_size:\n",
        "        split_idx = text.rfind(\".\", 0, max_chunk_size) + 1\n",
        "        if split_idx == 0:\n",
        "            split_idx = max_chunk_size\n",
        "        chunks.append(text[:split_idx].strip())\n",
        "        text = text[split_idx:].strip()\n",
        "    if text:\n",
        "        chunks.append(text)\n",
        "    return chunks\n",
        "\n",
        "corpus = chunk_text(all_text)\n",
        "\n",
        "# ✅ Save corpus for reuse\n",
        "import pickle\n",
        "with open(\"corpus.pkl\", \"wb\") as f:\n",
        "    pickle.dump(corpus, f)\n",
        "\n",
        "print(f\"✅ Corpus created with {len(corpus)} chunks.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpFP-w8Sg0J3",
        "outputId": "f74cc8e4-7e66-499c-cf19-9937c5bd6b69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Combined total chunks: 2505\n"
          ]
        }
      ],
      "source": [
        "#step4\n",
        "def chunk_text(text, max_chars=1000):\n",
        "    lines = text.split(\"\\n\")\n",
        "    chunk = \"\"\n",
        "    chunks = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip():\n",
        "            if len(chunk) + len(line) < max_chars:\n",
        "                chunk += line + \" \"\n",
        "            else:\n",
        "                chunks.append(chunk.strip())\n",
        "                chunk = line + \" \"\n",
        "    if chunk:\n",
        "        chunks.append(chunk.strip())\n",
        "    return chunks\n",
        "\n",
        "# Chunk each law\n",
        "ipc_chunks = chunk_text(ipc_text)\n",
        "crpc_chunks = chunk_text(crpc_text)\n",
        "iea_chunks = chunk_text(iea_text)\n",
        "\n",
        "# Combine all chunks\n",
        "corpus = ipc_chunks + crpc_chunks + iea_chunks\n",
        "\n",
        "# Save combined corpus\n",
        "import pickle\n",
        "with open(\"corpus.pkl\", \"wb\") as f:\n",
        "    pickle.dump(corpus, f)\n",
        "\n",
        "print(f\"✅ Total combined chunks: {len(corpus)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582,
          "referenced_widgets": [
            "2cc4f56f9d9848e08769258a98ddf47f",
            "01163e00357e426d92025b2fa12f5dac",
            "45d777011b774d43866d0104d40d9791",
            "8c9e96054e7445be8da12db4125312df",
            "accef9a6adf2415a9f7b9c2589611c9d",
            "b8f672f42cb14d52920f58084e15e111",
            "588728c38e9d4774aca28dc9a27ddaf9",
            "a436f7ee61e14aa8866fdfaa181d9bee",
            "097dce27b5bc41e5858c3afc08c95d95",
            "90d418e0a8ea4d40b0ce8291352a4cc6",
            "f1a1bc807f424b70900d882ab7e91d22",
            "b4e6161dcd28465d94fb46a15795f064",
            "898b232f55dc460fa52a59c1c49134a2",
            "0a35b7ed650342ae93dab8d5e13e2cb1",
            "99f966dd69d44d8487dcd4be69033af0",
            "280a2dc0b1314aca9ca555655e5a1125",
            "92b80fafe37647a1abb91823e509980c",
            "893fb706b5df42b592fc9a81a0a8646f",
            "cae974d7acb645d8b405e8d563292f82",
            "70f716256c1f466885a00bef03280129",
            "d0ba373e7e7842948c986a2c0d7ec250",
            "f1067f84917b47cca08d79a36bfc10a0",
            "0b100d73760641fc9052ea3bb00bf09a",
            "9c1bdd9b59c947ccaa2f0e6e61c12c0c",
            "76d9d80439f946dabd85f744e2ff435f",
            "290c683d7ed34a16b7b98140895f22b4",
            "f6eaabe90dbe4c699b1ec518ac110c4d",
            "195827b99fc14c669070289cf3b1a6dd",
            "db764a873f5349ebad867af09f0cc820",
            "d5b09a86ef904ae0bb8782fc99f40d13",
            "261211c5efc44adc9e0f9d2a7b0a70a7",
            "5eaab3f4735542dba39ae37654636057",
            "5e61b870ef0f48a1ae2d0c4b31d9d158",
            "5b59cfe377b34202b4c7551a8953fc83",
            "882d18c3206948d89f711b4f5cf25c46",
            "aecffbffafa641b7bb15a8ccb297d823",
            "bb84857b699e48ac9561267d6c90fedd",
            "8811bf0a7bb248d7898c7d315dad51eb",
            "2ac3f78af0084ffb821f8df6595d5c73",
            "a964da554f7248a5955efc76a16ab9fe",
            "e98ae79218944e81baf67d6fb3de50d2",
            "15b4398092304b91b18b408f9408387c",
            "aa0d49eef60040ebae7be57cce631973",
            "1382a389bc4d45cbb9f0837c7fa4659a",
            "b4732568d91449c98403e5431a4b54f8",
            "04e089a648914be28033e063caa97a4f",
            "e3ef59982e7340aa8cb479075afa5f9d",
            "5b7e132ae3e14131b2251b64b15e76cd",
            "ed03784b4e214fecb9c7532413cb6192",
            "7845a7de4993470fa2fab3353342fd28",
            "f28b9688675a427ca5d48b299e9c21e2",
            "824f3a4240204edda286c059266fb862",
            "d04feaa8675b4836b09f6c2b1e1521b2",
            "303108867777488ea60bb2b7ac35f845",
            "16b84cc28ff04a119078c30e306dec4f",
            "ada098d560fe463fb3790cedfeadf995",
            "57e0990d0116437783ab7b25580550eb",
            "ecaf61802a564345953cf7224a02ec65",
            "b923a43f8bbd44c4a82c055cd57e8fee",
            "8372e06071454416bb399a943e00bf72",
            "f6611a1e0ab44801b7979b02af953cc5",
            "73d4e00a88094c0486a33d9e30c547cf",
            "8ac5ab48a0a74019899f99b956ce4bd2",
            "23e6b382b969400aa1180a67df5211d4",
            "cb23751bad1948c28dcd277d6ac66e23",
            "d3b48000b1d24e57943ebbb75a98806e",
            "948aed8f28cd41148f3c27ddadcf7837",
            "e771c229a71245b6902f6375cfe38552",
            "38a7cbadf849441fb6d467886b78729d",
            "c10a6d2cda264cd79453eeb32d28c490",
            "c0a048c81d0e479999529c68b0979b3b",
            "f8b6f98c6c2a45dc8cfe9806eef26a6f",
            "69076ff255b2487bbca889b43f47cc9c",
            "caf9e1cbcd5d42099fe91b15305c874d",
            "b5a779dda5594845a7e84ec40109bbbc",
            "187991b4866940aea1f324ccf04a201b",
            "88fdcfbce1534671a42500bc34bc22fd",
            "25bcd2f22f684991a7d0af351c036de6",
            "fd56040fe7cc41569f93c800c9151cd5",
            "8c496bd0b0f9410eba020e1d1ee4ae83",
            "59d198ce22ba41739c788a473ba8b84c",
            "f5d2778315574fe98e08f8935c366953",
            "87d8379917c0437cb5efc79faa2c8818",
            "15b5ba567a5c4c53b3fbd98febac4c03",
            "7d3702db78924e3b8927ca8bc8885418",
            "1663fa1dd808423fb42adf5ee6883830",
            "e059103e3fca4ad48e20ac8fba8dbe42",
            "3ac53f5c7f6c4c41aca02ad27a6929e8",
            "bd8a6ea3214a4d5ba86c62eb8d08b347",
            "16f24939b8944e529a46fbd42d3f9f7a",
            "43313cc761234268b4794e4d834ddc29",
            "331ffc51573c447e95c19bb46e03e929",
            "c2b4d36bf99a48d1aefff88e5c872942",
            "8d975a45a5cc4d528b36e2f1f8465d90",
            "51e304ae7b964b41afb6d277462cd7b4",
            "1cbb16d62e924fa8b70fdc0a719096e3",
            "8184a14c8286476f88dfb33be57d5ebc",
            "849d33426b2641aea84297e7d10c6d19",
            "6e1d55251ad24157ab84626e7bd297e3",
            "7b528dce6f0d4981ba5550eed76fb5a3",
            "dcb96fbe904745ab9d8b4369f4fcc6d3",
            "e89b5387bf77497fa29fffb751a52971",
            "b7d148cc0f554816894d0dbb848843c3",
            "f79781c7197a46fe840e8607fa491578",
            "472eee3966df4811a63e47d83d109491",
            "2bac5303493949c0a4c8f5209d021efb",
            "f3f8bfa7380946e9974a5a55ed53daff",
            "87a1c7256306415cb26e136b35878f40",
            "846cb63cd62244a9b9bb503e4e0c14fe",
            "c9f269f6bde7432184099ac5c74f8221",
            "cfa660ce4ead4656ace25bcb6f69be7a",
            "e6a421e095fc4f02b4d3d47eaa39851d",
            "1240d7ad60c04f598adaf7dc762f7d72",
            "ed7e56bd052c4ac5b6b183ec0261f2df",
            "413add274b354cb9a3695b958d26dd6d",
            "a28a69abbb1f48f6b2e1dade8d771968",
            "e0cbd298a81e446bb0e7d85e25893e63",
            "89fbf183d918436ab087121b5b6d9f99",
            "e3968e532463451d898bdb7d4cc9f793",
            "cfcb547512e049e08a6573b038889c82",
            "08b9fbdeeac942d0ba6c9cbd2614897e",
            "8eab5296ae02426fa9d30bbe7793881d",
            "67f0b4a052d94d99ae074eebde6fddaf",
            "e314826f53554b48ad719474b0f97593",
            "dfefc0e29c484dd0b3a8081f052e10ca",
            "66e28db8b0194255a54b32862c6db6f1",
            "4040f3b1f2ce4962bd79e53b24aa6a59",
            "72e8562b03dd4b628cd20644142e0d5a",
            "ade9529ae3184925821652f822ff3d30",
            "b072d502b2504a69854e08be1aa05caa",
            "d4c59ad7d5114ea1bcae019cf942918e",
            "39b1c7b057aa4340b6de0c6594137e1d"
          ]
        },
        "id": "40eQaivskS21",
        "outputId": "7c2dc7b3-2d61-402a-bc4c-f518f8ab14a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cc4f56f9d9848e08769258a98ddf47f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4e6161dcd28465d94fb46a15795f064",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b100d73760641fc9052ea3bb00bf09a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b59cfe377b34202b4c7551a8953fc83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4732568d91449c98403e5431a4b54f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ada098d560fe463fb3790cedfeadf995",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "948aed8f28cd41148f3c27ddadcf7837",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25bcd2f22f684991a7d0af351c036de6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd8a6ea3214a4d5ba86c62eb8d08b347",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b528dce6f0d4981ba5550eed76fb5a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfa660ce4ead4656ace25bcb6f69be7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8eab5296ae02426fa9d30bbe7793881d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/79 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ FAISS index built and saved.\n"
          ]
        }
      ],
      "source": [
        "# ✅ Step 5: Build and Save FAISS Index\n",
        "from sentence_transformers import SentenceTransformer # Import the SentenceTransformer class\n",
        "\n",
        "model = SentenceTransformer(\"all-mpnet-base-v2\") # Assign the model to the variable 'model'\n",
        "corpus_embeddings = model.encode(corpus, show_progress_bar=True)\n",
        "dimension = corpus_embeddings[0].shape[0]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(corpus_embeddings))\n",
        "faiss.write_index(index, \"faiss_index.index\")\n",
        "print(\"✅ FAISS index built and saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350,
          "referenced_widgets": [
            "072824496d3f4c63a135f51a133f9abe",
            "0333dfbebd404f95acd94bac2e55c75e",
            "17a44355808b437c88618d90d37429bd",
            "59074ded23cf45b0b972b7579b843a7d",
            "c62089dd842a44c181d3c28c15fa18d2",
            "d97397767f1a4f7f925603ebdad26d28",
            "b56977c0fbff4407b61051c47c8728c0",
            "432aeebece624ceb9266ac89ea551f44",
            "55d1bbfce1d74f98a533cdcba6bf52ad",
            "d77a6b40b54a485eb0950083dadf8e2e",
            "15e9e1bae1ed4181b63f5a1578231db1",
            "7f310e068a244b93987d8678148deee5",
            "588ddac358334bdeb44aa1f424d57be9",
            "0384ae89ab5f4bff8b1828ef676d4ce4",
            "6dd9a4e887e945f4b9e587dcc05f5ab8",
            "d5fcb6eecb334083b2ce2b7427b9e3f0",
            "7ae9c9cbc19f4b40b47600a50823b761",
            "147ba7450d054ab9a2a6cc92ac0ee9c2",
            "04df6ae6315e47e28ca907b673da0853",
            "53f790ff005c4478a7395be009a4605a",
            "14f5417bb82e45bf8c2041a0ab2b36ee",
            "86de2969e39548eeadff604c39ab0e12",
            "25cb65926c534f759da0760622c417f5",
            "79ee5281f2844be38aeb4ffff08fac43",
            "451ff620ae124c19bbb52dc2f710c30c",
            "6b41b68fdffb438da96c6208065a379e",
            "fdcb1577f09847c7ac983899dc45a500",
            "33573ac9957546199f01307430249889",
            "b44fa8a19e024ea3bdc39097ad29b0a3",
            "aa55561280fd470082f4d4ed77a23d05",
            "e478c009e8714f758f1808069cbf64e5",
            "5c8ba2e1d71d407db5a2eed24d952fe1",
            "b13a3a2a9fa14ffda70d65ae180eeb7c",
            "9997a101adde4d789ccad1a9bf324502",
            "c298a8300bb946c8950b00371ef3d100",
            "dac8ec15e2af4a75bc0b4ccdb87267dd",
            "a2c452c25fde456895a84b0504b89f5b",
            "37600c92ef56418c9660fd4816788b20",
            "46bd8dbfe9a949d59f23616f0f1c888b",
            "73226914bd1f42099a1625d7b0c9dbec",
            "a182c7ae230a4e469da610734552f5ec",
            "4a6822f788c54e40a04ab5b36e8ba31d",
            "9d1a8003f8914a94ad0830ea0a0e5653",
            "441a81bd582a4d69a2ab53977b8ad836",
            "c2ef97372de9420e8b2739032f542651",
            "938bf71a9454420b978ec19a2dea2fe6",
            "f2c6e6be4c9f459f8b31687f1979cb68",
            "40428b80f06249b786e9571c21d6cb7e",
            "6b643ad67f834cd2a3741d1086c60462",
            "cc8761ec71954c2fa691669e8b343764",
            "bbff63afa1f34dc39558d227594768c6",
            "c478e3919cc0454b9395b9be54ad4555",
            "55cb29a57ae54d2184b768928301338a",
            "fd7b8d4c205741b68199415c3d26f016",
            "386f436a88a742ec8d1dcf619c13113d",
            "86d2bf7b930140da9dcf9e716f51d95d",
            "adfcdbfe3d7d411aaed229f0241f035a",
            "9b7eff0341134f74bfebf0dc0a278c31",
            "966a7cf8ba2448d79e09827d10f4949c",
            "525a4f41fc9f42b4a6a939cce0860da3",
            "9e17c4688e9641e2aec0ed7701c135b2",
            "6484e0b76e984d0597a377c250802cce",
            "9196646a9227495d936a6fc7c655691f",
            "144776c5a24645fd8745476f83416df0",
            "71972694482a4c1b8ea61de0194e901b",
            "492532b25ec342b3a61a4a56fc986270",
            "ed330813411a458995ae02dca528c0a3",
            "93f4f798bc924b5392f2811bbc4c2fb3",
            "14ef75bd4d5446a1ac315969c701d1e2",
            "1abb74a755fe49db84a5ffaed5d7107f",
            "e4f2c40d6c4443e583d58e9bb1a7e250",
            "035636f637d044c48f36050d0e8a299a",
            "98e9b5fa172342ddbe10744be28468a6",
            "dd53bd2177ad48738930ea7933d25c0f",
            "406c2670bfd545a5bd7323c2edeb5f3a",
            "21f86a78ce82421dbea7b0b42e66fff1",
            "036d4e2a4a8e4c75a0c2b33666fb44c6"
          ]
        },
        "id": "ZN7yYqFQgVcL",
        "outputId": "cd5a3081-0b72-4eda-cc8c-b54b0c11ebd5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "072824496d3f4c63a135f51a133f9abe",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f310e068a244b93987d8678148deee5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25cb65926c534f759da0760622c417f5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9997a101adde4d789ccad1a9bf324502",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2ef97372de9420e8b2739032f542651",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86d2bf7b930140da9dcf9e716f51d95d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed330813411a458995ae02dca528c0a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# ✅ Step 6: Load Free Generator Model\n",
        "generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGy0CP3Yz8ph"
      },
      "outputs": [],
      "source": [
        "#step 7\n",
        "\n",
        "def retrieve_docs(query, top_k=7):\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "    D, I = index.search(np.array(query_embedding), top_k)\n",
        "    results = [corpus[i] for i in I[0]]\n",
        "\n",
        "    match = re.search(r\"\\b(\\d+[A-Za-z]*)\\b\", query)\n",
        "    if match:\n",
        "        token = match.group(1)\n",
        "        if not any(token in doc for doc in results):\n",
        "            fallback = [doc for doc in corpus if token in doc]\n",
        "            if fallback:\n",
        "                results = fallback[:top_k]\n",
        "    return results\n",
        "\n",
        "def answer_query(query):\n",
        "    docs = retrieve_docs(query)\n",
        "    context = \"\\n\\n\".join(docs)\n",
        "\n",
        "    section_match = re.search(r\"(Section\\s\\d+[A-Za-z]*)\", context)\n",
        "    cited_section = section_match.group(1) if section_match else \"an applicable IPC section\"\n",
        "\n",
        "    q = query.lower()\n",
        "    if \"theft\" in q and \"robbery\" in q:\n",
        "        answer = (\n",
        "            f\"📘 According to IPC Sections 378 and 390:<br>\"\n",
        "            f\"<b>Theft</b>: Dishonestly taking someone's property without consent.<br>\"\n",
        "            f\"<b>Robbery</b>: Theft or extortion with violence or threat of harm.<br><br>\"\n",
        "            f\"➡️ So, robbery = theft/extortion + violence/threat.\"\n",
        "        )\n",
        "    elif \"bailable\" in q and \"non-bailable\" in q:\n",
        "        answer = (\n",
        "            \"📘 As per CrPC:<br>\"\n",
        "            \"<b>Bailable offence</b>: Bail is a right.<br>\"\n",
        "            \"<b>Non-bailable offence</b>: Bail is at the court's discretion.\"\n",
        "        )\n",
        "    elif \"120b\" in q:\n",
        "        answer = (\n",
        "            \"📘 IPC Section 120B:<br>\"\n",
        "            \"<b>Criminal Conspiracy</b>: Same punishment as the offence conspired if it's serious.<br>\"\n",
        "            \"Otherwise: Imprisonment up to 6 months or fine or both.\"\n",
        "        )\n",
        "    else:\n",
        "        prompt = (\n",
        "            \"You are a legal expert assistant specialized in Indian law. \"\n",
        "            \"Based solely on the following legal context, provide an accurate and relevant answer.\\n\\n\"\n",
        "            f\"Context:\\n{context}\\n\\n\"\n",
        "            f\"Question: {query}\\n\"\n",
        "            \"Answer:\"\n",
        "        )\n",
        "        result = generator(prompt, max_length=256, do_sample=False, temperature=0.3, top_p=0.95)\n",
        "        answer = f\"📘 According to {cited_section}:<br>{result[0]['generated_text']}\"\n",
        "\n",
        "    logo_html = f'<img src=\"data:image/png;base64,{logo_base64}\" width=\"50\"/>'\n",
        "    header = f\"{logo_html} <b>🤖 Turn2Bot – Your Legal Companion ⚖️</b><br><br>\"\n",
        "    final_answer = header + answer\n",
        "    return final_answer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "-SAiwNouJygf",
        "outputId": "2d65b2a3-526d-4f43-bb27-6540b64197b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://d597b76ea01b4ea589.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://d597b76ea01b4ea589.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#step8 ✅ Initial display message with logo\n",
        "import base64\n",
        "\n",
        "# Helper function: Convert image file to Base64 string\n",
        "def image_to_base64(path):\n",
        "    with open(path, \"rb\") as f:\n",
        "        data = f.read()\n",
        "    return base64.b64encode(data).decode(\"utf-8\")\n",
        "\n",
        "# Convert your logo image to base64 (ensure your logo exists at logo_assets/logo.png)\n",
        "logo_b64 = image_to_base64(\"logo_assets/logo.png\")\n",
        "\n",
        "gr.Interface(\n",
        "    fn=answer_query,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"e.g., What is IPC Section 120B?\"),\n",
        "    outputs=\"text\",\n",
        "    title=\" Turn2Bot – Your Legal Companion ⚖️\",\n",
        "    description=f\"\"\"\n",
        "<div align=\"center\">\n",
        "    <img src=\"data:image/png;base64,{logo_b64}\" width=\"100\"/>\n",
        "</div>\n",
        "<br>\n",
        "Ask any Indian law-related question based on the Indian Penal Code. 🇮🇳\n",
        "\n",
        "Note: This is not legal advice. Please consult a qualified lawyer for legal matters.\n",
        "\"\"\",\n",
        "    theme=\"default\"\n",
        ").launch()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}